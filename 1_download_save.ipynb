{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe7cf3eb",
   "metadata": {},
   "source": [
    "# Download the module from Hugging Face \n",
    "\n",
    "The easiest way to download the model is by using Hugging Face. To configure the module, uncomment the line corresponding to the desired module. Ensure both HF_USER and HF_TOKEN are set as environment variables in the workbench.\n",
    "\n",
    "You can also manually download the model files if your environment is not able to reach out to the internet. Navigate to the \"Files and versions\" tab on your Hugging Face module page (e.g., https://huggingface.co/ibm-granite/granite-7b-instruct/tree/main) and download the files. Use CLI tools or a browser to upload these files to your S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b510f1",
   "metadata": {},
   "source": [
    "## Download Model from Huggingface\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "320aad95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'granite-7b-instruct'...\n",
      "remote: Enumerating objects: 55, done.\u001b[K\n",
      "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
      "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
      "remote: Total 55 (delta 18), reused 0 (delta 0), pack-reused 1 (from 1)\u001b[K\n",
      "Unpacking objects: 100% (55/55), 1.36 MiB | 8.91 MiB/s, done.\n",
      "Filtering content: 100% (4/4), 4.55 GiB | 14.73 MiB/s, done.\n",
      "Model Directory: granite-7b-instruct\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Choose the desired model\n",
    "# my_repo = \"huggingface.co/ibm-granite/granite-7b-instruct\"\n",
    "# my_repo = \"huggingface.co/ibm/merlinite-7b\"\n",
    "# my_repo = \"huggingface.co/instructlab/merlinite-7b-lab\"\n",
    "# my_repo = \"https://huggingface.co/mistralai/Mistral-7B\"\n",
    "# my_repo = \"https://huggingface.co/codellama/CodeLlama-7b-hf\"\n",
    "# my_repo = \"https://huggingface.co/mosaicml/mpt-7b-chat\"\n",
    "# my_repo = \"https://huggingface.co/mosaicml/mpt-7b-instruct\"\n",
    "\n",
    "# Ensure my_repo is set\n",
    "my_repo = \"huggingface.co/ibm-granite/granite-7b-instruct\"  # Example default, change as needed\n",
    "if not my_repo:\n",
    "    raise ValueError(\"Please uncomment or set the 'my_repo' variable.\")\n",
    "\n",
    "# Prepare the GitHub repository URL with authentication\n",
    "git_repo = f\"https://{os.getenv('HF_USER')}:{os.getenv('HF_TOKEN')}@{my_repo}\"\n",
    "\n",
    "# Extract model directory name\n",
    "model_dir = os.path.basename(my_repo)\n",
    "\n",
    "# Clone or update the repository\n",
    "if not os.path.exists(model_dir):\n",
    "    !git clone $git_repo\n",
    "else:\n",
    "    %cd $model_dir\n",
    "    !git fetch --all\n",
    "    !git reset --hard origin/main\n",
    "    %cd ..\n",
    "\n",
    "print(f\"Model Directory cloned in: {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a6e16d",
   "metadata": {},
   "source": [
    "## Configure S3 Bucket Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6c6ceec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 connectivity established successfully for the bucket: mys3-1efde082-92ab-47ae-8b56-15e3b6fed5aa\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "\n",
    "# Fetch required environment variables\n",
    "aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "endpoint_url = os.getenv('AWS_S3_ENDPOINT')\n",
    "region_name = os.getenv('AWS_DEFAULT_REGION')\n",
    "bucket_name = os.getenv('AWS_S3_BUCKET')\n",
    "\n",
    "if not all([aws_access_key_id, aws_secret_access_key, endpoint_url, region_name, bucket_name]):\n",
    "    raise EnvironmentError(\"Ensure all AWS-related environment variables are properly set.\")\n",
    "\n",
    "# Create a Boto3 session\n",
    "session = boto3.session.Session(\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key\n",
    ")\n",
    "\n",
    "# Set up S3 resource with session\n",
    "s3_resource = session.resource(\n",
    "    's3',\n",
    "    config=botocore.client.Config(signature_version='s3v4'),\n",
    "    endpoint_url=endpoint_url,\n",
    "    region_name=region_name\n",
    ")\n",
    "\n",
    "# Connect to the specified bucket\n",
    "bucket = s3_resource.Bucket(bucket_name)\n",
    "print(f\"S3 connectivity established successfully for the bucket: {bucket_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a013aa",
   "metadata": {},
   "source": [
    "## Upload model to S3 bucket"
   ]
  },
  {
   "cell_type": "raw",
   "id": "38355731-3e64-4bee-8dd5-09fa0f5a73a7",
   "metadata": {},
   "source": [
    "def upload_directory_to_s3(local_directory, s3_prefix):\n",
    "    \"\"\"\n",
    "    Uploads files from a local directory to an S3 bucket under a specific prefix.\n",
    "\n",
    "    Parameters:\n",
    "        local_directory (str): Path to the local directory to upload.\n",
    "        s3_prefix (str): S3 prefix (folder path) to upload files to.\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(local_directory):\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(root, filename)\n",
    "            relative_path = os.path.relpath(file_path, local_directory)\n",
    "            \n",
    "            # Skip .git files and folders\n",
    "            if \".git\" in relative_path:\n",
    "                print(f\"Skipping {relative_path}\")\n",
    "                continue\n",
    "\n",
    "            # Ensure proper S3 path formatting\n",
    "            s3_key = os.path.join(s3_prefix, relative_path).replace(\"\\\\\", \"/\")\n",
    "            print(f\"Uploading {file_path} -> {s3_key}\")\n",
    "            bucket.upload_file(file_path, s3_key)\n",
    "\n",
    "\n",
    "def list_objects(prefix):\n",
    "    \"\"\"\n",
    "    Lists all objects under a given prefix in the S3 bucket.\n",
    "\n",
    "    Parameters:\n",
    "        prefix (str): The S3 prefix to list objects under.\n",
    "    \"\"\"\n",
    "    print(f\"Objects under prefix '{prefix}':\")\n",
    "    for obj in bucket.objects.filter(Prefix=prefix):\n",
    "        print(obj.key)\n",
    "\n",
    "\n",
    "print(f\"Starting upload of model directory '{model_dir}' to S3...\")\n",
    "\n",
    "# Upload model to S3\n",
    "upload_directory_to_s3(model_dir, f\"models/{model_dir}\")\n",
    "\n",
    "print(f\"Upload complete. Verifying uploaded files in S3 under 'models/{model_dir}'...\\n\")\n",
    "\n",
    "# Verify uploaded files\n",
    "list_objects(f\"models/{model_dir}\")\n",
    "\n",
    "print(\"\\nVerification complete. All objects listed above are now available in S3.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5682b922",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "Now that the model is uploaded to S3 storage, you can deploy your model configure the ServingRuntime and InferenceEndpoint from the Workbanch models tab."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
